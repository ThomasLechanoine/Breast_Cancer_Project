{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20f9146-68f1-4266-b3ef-b550c784c198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: numpy>=1.19.3 in /home/thomas/.pyenv/versions/3.10.6/envs/breast_cancer_project/lib/python3.10/site-packages (from opencv-python) (2.0.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f1bc76-22de-4917-a366-f428f3d448d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 10:36:58.434704: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-13 10:36:58.644528: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-13 10:36:58.807362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741858618.945081    1444 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741858618.983362    1444 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-13 10:36:59.322758: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b316db53-a892-460c-84c6-805d8f646f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Chemins ===\n",
    "input_dir = os.path.join(\"wsl.localhost\", \"Ubuntu\", \"home\",\"thomas\",\"code\",\"ThomasLechanoine\",\"projet\",\"data\",\"Image_2_Breast_Cancer\")\n",
    "output_dir = os.path.join(\"wsl.localhost\", \"Ubuntu\",\"home\",\"thomas\",\"code\",\"ThomasLechanoine\",\"projet\",\"data,processed_images\")\n",
    "\n",
    "# === Création du dossier de sortie avec la même structure ===\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    for label in [\"0\", \"1\"]:\n",
    "        os.makedirs(os.path.join(output_dir, split, label), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac09b823-6fb8-4684-9d7c-439bc5ab608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'UsersASUSDesktopPreproTL': No such file or directory\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83cf40cf-473e-4253-9968-9c294a33c2c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wsl.localhost/Ubuntu/home/thomas/code/ThomasLechanoine/projet/data/Image_2_Breast_Cancer/train/0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, split, label)\n\u001b[1;32m     22\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, split, label)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m) :\n\u001b[1;32m     26\u001b[0m         input_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wsl.localhost/Ubuntu/home/thomas/code/ThomasLechanoine/projet/data/Image_2_Breast_Cancer/train/0'"
     ]
    }
   ],
   "source": [
    "# === Fonction de prétraitement ===\n",
    "def preprocess_image(image_path, output_path):\n",
    "    \"\"\"Charge une image, la prétraite et l'enregistre sans écraser l'originale.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    # Réduction du bruit\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "\n",
    "    # Normalisation entre 0 et 1\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "\n",
    "    # Sauvegarde (convertie en 0-255 pour éviter perte de qualité)\n",
    "    img = (img * 255).astype(\"uint8\")\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# === Prétraitement de toutes les images ===\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    for label in [\"0\", \"1\"]:\n",
    "        input_folder = os.path.join(input_dir, split, label)\n",
    "        output_folder = os.path.join(output_dir, split, label)\n",
    "\n",
    "        for filename in os.listdir(input_folder):\n",
    "            if filename.endswith(\".jpg\") :\n",
    "                input_path = os.path.join(input_folder, filename)\n",
    "                output_path = os.path.join(output_folder, filename)\n",
    "                preprocess_image(input_path, output_path)\n",
    "\n",
    "print(\"✅ Prétraitement terminé !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff3c64d7-1438-4502-9398-9ca532cfbc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/thomas/code/ThomasLechanoine/projet/data/Image_2_Breast_Cancer/train/0': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls -ld /home/thomas/code/ThomasLechanoine/projet/data/Image_2_Breast_Cancer/train/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54bea00-6972-4d32-9366-5d36275526da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Comptage des images par classe pour équilibrage ===\n",
    "num_images = {label: len(os.listdir(os.path.join(output_dir, \"train\", label))) for label in [\"0\", \"1\"]}\n",
    "print(f\"📊 Nombre d'images : {num_images}\")\n",
    "\n",
    "# === Définir la classe majoritaire et minoritaire ===\n",
    "majority_class = \"0\" if num_images[\"0\"] > num_images[\"1\"] else \"1\"\n",
    "minority_class = \"1\" if majority_class == \"0\" else \"0\"\n",
    "\n",
    "# === Facteur d'augmentation pour équilibrer les classes ===\n",
    "augmentation_factor = num_images[majority_class] // num_images[minority_class]\n",
    "print(f\"📈 Augmentation de la classe {minority_class} x{augmentation_factor}\")\n",
    "\n",
    "# === Data Augmentation uniquement pour la classe minoritaire ===\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "minority_folder = os.path.join(output_dir, \"train\", minority_class)\n",
    "for filename in os.listdir(minority_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        img_path = os.path.join(minority_folder, filename)\n",
    "        img = tf.keras.utils.load_img(img_path)\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        # Générer plusieurs augmentations\n",
    "        aug_iter = datagen.flow(img_array, batch_size=1)\n",
    "        for i in range(augmentation_factor - 1):  # -1 car on a déjà l'image originale\n",
    "            aug_img = next(aug_iter)[0].astype(\"uint8\")\n",
    "            aug_filename = f\"aug_{i}_{filename}\"\n",
    "            aug_img_path = os.path.join(minority_folder, aug_filename)\n",
    "            tf.keras.preprocessing.image.save_img(aug_img_path, aug_img)\n",
    "\n",
    "print(\"✅ Augmentation terminée !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829f4fa-5bf3-43c4-84f5-7e8525ea49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Chargement des images avec tf.data ===\n",
    "def load_and_preprocess(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [224, 224])\n",
    "    img = img / 255.0  # Normalisation\n",
    "    return img, label\n",
    "\n",
    "def get_dataset(split):\n",
    "    images = []\n",
    "    labels = []\n",
    "    v\n",
    "    for label in [\"0\", \"1\"]:\n",
    "        folder = os.path.join(output_dir, split, label)\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                images.append(os.path.join(folder, filename))\n",
    "                labels.append(int(label))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    dataset = dataset.shuffle(len(images)).map(load_and_preprocess).batch(32)\n",
    "    return dataset\n",
    "\n",
    "# Charger les datasets\n",
    "train_dataset = get_dataset(\"train\")\n",
    "valid_dataset = get_dataset(\"valid\")\n",
    "test_dataset = get_dataset(\"test\")\n",
    "\n",
    "print(\"✅ Chargement des datasets terminé !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
