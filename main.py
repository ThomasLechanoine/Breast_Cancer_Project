import os
import numpy as np
import joblib
import pandas as pd
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, LabelEncoder
from Machine_learning.ml_preprocess import load_data, preprocess_data
from Machine_learning.ml_model import create_model, tune_hyperparameters, evaluate_model
from params import *
import tensorflow as tf

# ------------------------
# ğŸ“Œ Imports du Deep Learning
from Deep_learning.dl_model import (
    create_feature_extractor,
    dl_initialize_edRVFL,
    dl_compile_model,
    dl_train_model
)
from Deep_learning.dl_custom_dataset import load_custom_dataset
from Deep_learning.dl_preprocess import extract_features




import sys
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

# ---------------------
# ğŸ“Œ Charger les modÃ¨les (Ã©vite le rechargement multiple)
def load_models():
    print("ğŸ”„ Chargement des modÃ¨les...")
    dl_model = load_model(DL_MODEL_PATH)
    ml_model = joblib.load(ML_MODEL_PATH)
    scaler = joblib.load(ML_SCALER_PATH)
    print("âœ… ModÃ¨les chargÃ©s avec succÃ¨s.")
    return dl_model, ml_model, scaler

# ğŸ“Œ PrÃ©traitement d'image pour le Deep Learning
def preprocess_image(image_path):
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)  # Ajouter une dimension batch
    return img_array

# ğŸ“Œ PrÃ©traitement des donnÃ©es tabulaires (Machine Learning)
def preprocess_ml_data(data_path):
    data = load_data(data_path)
    return preprocess_data(data)

# ğŸ“Œ EntraÃ®ner le modÃ¨le ML
def train_ml():
    print("ğŸ”„ EntraÃ®nement du modÃ¨le Machine Learning...")
    data = load_data(ML_DATA_PATH)
    X_train, X_test, y_train, y_test, scaler, le = preprocess_data(data)
    best_model = tune_hyperparameters(X_train, y_train)

    os.makedirs("models_saved", exist_ok=True)
    joblib.dump(best_model, ML_MODEL_PATH)
    joblib.dump(scaler, ML_SCALER_PATH)

    print("âœ… ModÃ¨le ML entraÃ®nÃ© et sauvegardÃ©.")

# ğŸ“Œ EntraÃ®ner le modÃ¨le DL
def train_dl():
    print("ğŸ” VÃ©rification des donnÃ©es...")
    if not os.path.exists(DL_DATASET_PATH):
        print(f"âŒ Erreur : Le dataset {DL_DATASET_PATH} n'existe pas.")
        return

    print("âœ… Chargement des images avec CustomImageDataset...")
    train_ds, val_ds = load_custom_dataset(DL_DATASET_PATH, DL_IMG_SIZE, batch_size=16)

    print("âœ… Extraction des caractÃ©ristiques avec VGG16...")
    feature_extractor = create_feature_extractor(DL_IMG_SIZE)

    print("ğŸ”„ Extraction des features pour train...")
    X_train_features, y_train = extract_features(feature_extractor, train_ds)
    print("ğŸ”„ Extraction des features pour validation...")
    X_val_features, y_val = extract_features(feature_extractor, val_ds)

    print(f"âœ… CaractÃ©ristiques extraites : X_train {X_train_features.shape}, y_train {y_train.shape}")

    print("âœ… Initialisation du modÃ¨le edRVFL...")
    input_dim = X_train_features.shape[1]
    model = dl_initialize_edRVFL(input_dim, num_classes=1, num_layers=5, hidden_units=50)

    print("ğŸ”„ Compilation du modÃ¨le...")
    model = dl_compile_model(model, optimizer=DL_OPTIMIZER, loss=DL_LOSS_FUNCTION, metrics=DL_METRICS)

    print("ğŸš€ EntraÃ®nement du modÃ¨le...")
    model, history = dl_train_model(model, X_train_features, y_train, X_val_features, y_val, epochs=DL_EPOCHS, batch_size=32)

    print(f"ğŸ”„ Sauvegarde du modÃ¨le en cours dans : {DL_MODEL_PATH}")
    os.makedirs(os.path.dirname(DL_MODEL_PATH), exist_ok=True)

    try:
        model.save(DL_MODEL_PATH)
        print(f"âœ… ModÃ¨le sauvegardÃ© avec succÃ¨s dans {DL_MODEL_PATH}")
    except Exception as e:
        print(f"âŒ Erreur lors de la sauvegarde du modÃ¨le : {e}")

# ğŸ“Œ Point d'entrÃ©e principal
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--train", choices=["ml", "dl", "all"], help="Lancer l'entraÃ®nement des modÃ¨les")
    parser.add_argument("--evaluate_dl", action="store_true", help="Ã‰valuer le modÃ¨le DL avec une matrice de confusion")
    parser.add_argument("--debug", action="store_true", help="Activer le mode debug")
    args = parser.parse_args()

    if args.debug:
        print("ğŸ” Mode DEBUG activÃ©")

    if args.train == "ml":
        train_ml()
    elif args.train == "dl":
        train_dl()
    elif args.train == "all":
        train_ml()
        train_dl()

    # ğŸ“Œ Nouvelle option pour Ã©valuer le modÃ¨le DL
    if args.evaluate_dl:
        print("ğŸ“Š Ã‰valuation du modÃ¨le Deep Learning en cours...")
        os.system("python Deep_learning/dl_evaluate.py")  # Appelle le script d'Ã©valuation
