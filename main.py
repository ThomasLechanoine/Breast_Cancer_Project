import os
import numpy as np
import joblib
import pandas as pd
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, LabelEncoder
from Machine_learning.ml_preprocess import load_data, preprocess_data
from Machine_learning.ml_model import create_model, tune_hyperparameters, evaluate_model
from Deep_learning.dl_model import dl_initialize_model, dl_compile_model, dl_train_model
from Deep_learning.dl_preprocess import download
from params import *
from tensorflow.keras.preprocessing import image_dataset_from_directory


# üìå Charger les mod√®les (√©vite le rechargement multiple)
def load_models():
    print("üîÑ Chargement des mod√®les...")
    dl_model = load_model(DL_MODEL_PATH)
    ml_model = joblib.load(ML_MODEL_PATH)
    scaler = joblib.load(ML_SCALER_PATH)
    print("‚úÖ Mod√®les charg√©s avec succ√®s.")
    return dl_model, ml_model, scaler

# üìå Pr√©traitement d'image pour le Deep Learning
def preprocess_image(image_path):
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)  # Ajouter une dimension batch
    return img_array

# üìå Pr√©traitement des donn√©es tabulaires (Machine Learning)
def preprocess_ml_data(data_path):
    data = load_data(data_path)
    return preprocess_data(data)

# üìå Entra√Æner le mod√®le ML
def train_ml():
    data = load_data(ML_DATA_PATH)
    X_train, X_test, y_train, y_test, scaler, le = preprocess_data(data)
    best_model = tune_hyperparameters(X_train, y_train)

    os.makedirs("models_saved", exist_ok=True)
    joblib.dump(best_model, ML_MODEL_PATH)
    joblib.dump(scaler, ML_SCALER_PATH)

    print("‚úÖ Mod√®le ML entra√Æn√© et sauvegard√©.")

# üìå Entra√Æner le mod√®le DL
def train_dl():
    # V√©rifier les donn√©es
    if not os.path.exists(DL_DATA_PATH):
        download()

    print("‚úÖ Chargement des images...")

    # Charger les datasets
    train_dataset = image_dataset_from_directory(
        os.path.join(DL_DATA_PATH, "train"),
        labels="inferred",
        label_mode="binary",
        batch_size=DL_BATCH_SIZE,
        image_size=DL_IMG_SIZE,
        shuffle=True
    )

    valid_dataset = image_dataset_from_directory(
        os.path.join(DL_DATA_PATH, "valid"),
        labels="inferred",
        label_mode="binary",
        batch_size=DL_BATCH_SIZE,
        image_size=DL_IMG_SIZE,
        shuffle=True
    )

    # Initialisation et entra√Ænement
    model = dl_initialize_model()
    model = dl_compile_model(model, optimizer=DL_OPTIMIZER, loss=DL_LOSS_FUNCTION, metrics=DL_METRICS)
    model, history = dl_train_model(model, train_dataset, valid_dataset, epochs=DL_EPOCHS)

    # Sauvegarde du mod√®le
    os.makedirs(os.path.dirname(DL_MODEL_PATH), exist_ok=True)
    try:
        print(f"üîÑ Sauvegarde du mod√®le en cours dans : {DL_MODEL_PATH}")
        model.save(DL_MODEL_PATH)
        print(f"‚úÖ Mod√®le sauvegard√© avec succ√®s dans {DL_MODEL_PATH}")
    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde du mod√®le : {e}")

# üìå Point d'entr√©e principal
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--train", choices=["ml", "dl", "all"], help="Lancer l'entra√Ænement des mod√®les")
    args = parser.parse_args()

    if args.train == "ml":
        train_ml()
    elif args.train == "dl":
        train_dl()
    elif args.train == "all":
        train_ml()
        train_dl()
